{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9978dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load files\n",
    "content = pd.read_csv('Content.csv')\n",
    "cities = pd.read_csv('Cities.csv')\n",
    "date = pd.read_csv('Date.csv')\n",
    "source = pd.read_csv('Traffic source.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daaabe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove first row (totals)\n",
    "content = content.iloc[1:]\n",
    "cities = cities.iloc[1:]\n",
    "date = date.iloc[1:]\n",
    "source = source.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0d6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime\n",
    "content['Video publish time'] = pd.to_datetime(content['Video publish time'])\n",
    "content['Duration'] = pd.to_timedelta(content['Duration'], unit='s')\n",
    "content['Watch time (hours)'] = pd.to_timedelta(content['Watch time (hours)'], unit='h')\n",
    "content['Average view duration'] = pd.to_timedelta(content['Average view duration'])\n",
    "content['Impressions click-through rate (%)'] = content['Impressions click-through rate (%)'] / 100\n",
    "content.rename(columns={'Impressions click-through rate (%)': 'Impressions CTR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c336a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "date['Date'] = pd.to_datetime(date['Date'])\n",
    "date['Watch time (hours)'] = pd.to_timedelta(date['Watch time (hours)'], unit='h')\n",
    "date['Average view duration'] = pd.to_timedelta(date['Average view duration'])\n",
    "\n",
    "cities['Watch time (hours)'] = pd.to_timedelta(cities['Watch time (hours)'], unit='h')\n",
    "cities['Average view duration'] = pd.to_timedelta(cities['Average view duration'])\n",
    "\n",
    "source['Watch time (hours)'] = pd.to_timedelta(source['Watch time (hours)'], unit='h')\n",
    "source['Average view duration'] = pd.to_timedelta(source['Average view duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2086d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Content                                        Video title  \\\n",
      "1  9rU6Jf1EpLg  I LOVE the new Jinx design #shorts #arcane #le...   \n",
      "2  RhvaJIXedtY  Season 2 Vi is ðŸ¥µðŸ¥µðŸ¥µðŸ¥µ #shorts  #arcane #leagueof...   \n",
      "3  B0MKg88uE1g  Maddie makes me ðŸ˜¡ðŸ˜¡ðŸ¤¬ðŸ˜  #arcane #leagueoflegends ...   \n",
      "4  Mk0-nA1Vad8  The most UNDERRATED enforcer #arcane #leagueof...   \n",
      "5  f40T4AbyJiI  Arcane's time travel explained! #arcane #leagu...   \n",
      "\n",
      "  Video publish time        Duration      Views          Watch time (hours)  \\\n",
      "1         2024-09-09 0 days 00:00:31  1348535.0 419 days 22:19:58.439999996   \n",
      "2         2024-09-22 0 days 00:00:32   735917.0    216 days 00:57:31.320000   \n",
      "3         2024-11-27 0 days 00:00:23   638341.0    189 days 13:29:33.360000   \n",
      "4         2024-11-28 0 days 00:00:29   587002.0    200 days 23:41:38.400000   \n",
      "5         2024-11-25 0 days 00:00:26   546862.0    216 days 13:29:51.720000   \n",
      "\n",
      "   Subscribers Average view duration  Impressions  Impressions CTR  \n",
      "1        604.0       0 days 00:00:26     12336850           0.0746  \n",
      "2        709.0       0 days 00:00:25      6137555           0.0701  \n",
      "3        173.0       0 days 00:00:25      4046557           0.0758  \n",
      "4        129.0       0 days 00:00:29      1703376           0.0711  \n",
      "5        114.0       0 days 00:00:34       176044           0.0436  \n"
     ]
    }
   ],
   "source": [
    "print(content.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946387c",
   "metadata": {},
   "source": [
    "# Statistical Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763fe45",
   "metadata": {},
   "source": [
    "**Anova Test on Importance of Publishing Date and Runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead9a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Duration' to seconds if it's in a timedelta format\n",
    "content['Duration_sec'] = content['Duration'].dt.total_seconds()\n",
    "\n",
    "# Define bins for runtime (e.g., Short: <30s, Medium: 30-60s, Long: >60s)\n",
    "bins_runtime = [0, 30, 60, float('inf')]\n",
    "labels_runtime = ['Short', 'Medium', 'Long']\n",
    "content['Runtime_Category'] = pd.cut(content['Duration_sec'], bins=bins_runtime, labels=labels_runtime)\n",
    "\n",
    "# Extract day of the week from publish time (0 = Monday, 6 = Sunday)\n",
    "content['Publish_Day'] = content['Video publish time'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          sum_sq     df          F  \\\n",
      "C(Runtime_Category)                 6.139887e+11    2.0  21.666612   \n",
      "C(Publish_Day)                      1.162959e+11    6.0   1.367962   \n",
      "C(Runtime_Category):C(Publish_Day)  3.411711e+11   12.0   2.006558   \n",
      "Residual                            2.989660e+12  211.0        NaN   \n",
      "\n",
      "                                          PR(>F)  \n",
      "C(Runtime_Category)                 2.765491e-09  \n",
      "C(Publish_Day)                      2.288752e-01  \n",
      "C(Runtime_Category):C(Publish_Day)  2.502329e-02  \n",
      "Residual                                     NaN  \n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Drop rows with missing values in relevant columns\n",
    "anova_data = content.dropna(subset=['Views', 'Runtime_Category', 'Publish_Day'])\n",
    "\n",
    "# Run two-way anova on Runtime Category and Publish Day\n",
    "model = ols('Views ~ C(Runtime_Category) + C(Publish_Day) + C(Runtime_Category):C(Publish_Day)', data=anova_data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd51d9b",
   "metadata": {},
   "source": [
    "- According to their respective p-values, runtime had a statistically significant affect on view-count, whereas the publishing date did not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e35fc",
   "metadata": {},
   "source": [
    "**Z-Test on Importance of Runtime by Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b51a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Z-Score of Views per Runtime Category:\n",
      "Runtime_Category\n",
      "Medium    0.525609\n",
      "Short     0.437280\n",
      "Long     -0.344424\n",
      "Name: Views_Z, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aouzu\\AppData\\Local\\Temp\\ipykernel_8908\\497039492.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normalized_data['Views_Z'] = zscore(normalized_data['Views'])\n",
      "C:\\Users\\aouzu\\AppData\\Local\\Temp\\ipykernel_8908\\497039492.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  avg_zscores = normalized_data.groupby('Runtime_Category')['Views_Z'].mean().sort_values(ascending=False)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Drop missing values\n",
    "normalized_data = content.dropna(subset=['Views', 'Runtime_Category'])\n",
    "\n",
    "# Normalize the views using z-score\n",
    "normalized_data['Views_Z'] = zscore(normalized_data['Views'])\n",
    "\n",
    "# Group by runtime category and compute the average z-score\n",
    "avg_zscores = normalized_data.groupby('Runtime_Category')['Views_Z'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Average Z-Score of Views per Runtime Category:\")\n",
    "print(avg_zscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169e467",
   "metadata": {},
   "source": [
    "- Further analysis of runtime has shown that that a medium runtime of 30-60 seconds had the most postiive affect on view-count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd456705",
   "metadata": {},
   "source": [
    "**Tests on Correlation between City and Views**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61151f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_clean = cities.dropna(subset=['City name', 'Views', 'Average view duration']).copy()\n",
    "cities_clean['Views'] = pd.to_numeric(cities_clean['Views'], errors='coerce')\n",
    "\n",
    "# Normalize using z-score\n",
    "cities_clean['Views_Z'] = zscore(cities_clean['Views'])\n",
    "\n",
    "# Bin into 4 quartile categories based on z-score ranks\n",
    "cities_clean['Views_Quartile'] = pd.qcut(cities_clean['Views_Z'], 4, labels=['Q1', 'Q2', 'Q3', 'Q4'])  # Q1 = lowest views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f19de996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views Quartile vs City: Ï‡Â² = 1500.0000, p = 0.47330172\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency table\n",
    "views_table = pd.crosstab(cities_clean['City name'], cities_clean['Views_Quartile'])\n",
    "\n",
    "# Chi-square test\n",
    "chi2_v, p_v, dof_v, _ = chi2_contingency(views_table)\n",
    "print(f\"Views Quartile vs City: Ï‡Â² = {chi2_v:.4f}, p = {p_v:.8g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ed7b7",
   "metadata": {},
   "source": [
    "- The resulting p value shows that city has no statistically significant affect on view-count, and we don't necessarily have to appeal to any geographic location in particular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb6e55",
   "metadata": {},
   "source": [
    "**Exploring the effects of hashtags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e76505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content['Hashtags_List'] = content['Video title'].str.findall(r'#\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7402811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hashtags\n",
    "content['Hashtags_List'] = content['Video title'].str.findall(r'#\\w+')\n",
    "\n",
    "# Explode to get one row per hashtag\n",
    "hashtag_df = content.explode('Hashtags_List').dropna(subset=['Hashtags_List', 'Views'])\n",
    "\n",
    "# Clean\n",
    "hashtag_df['Views'] = pd.to_numeric(hashtag_df['Views'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count appearances and average views\n",
    "hashtag_stats = hashtag_df.groupby('Hashtags_List').agg(\n",
    "    count=('Views', 'count'),\n",
    "    avg_views=('Views', 'mean'),\n",
    "    std_views=('Views', 'std')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normalize data to account for outliers\n",
    "hashtag_stats['normalized_score'] = hashtag_stats['avg_views'] / np.log1p(hashtag_stats['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5527727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  count      avg_views      std_views  normalized_score\n",
      "Hashtags_List                                                          \n",
      "#leagueoflegends     57  142112.421053  230355.702197      34999.240399\n",
      "#shorts              74  140910.905405  205691.791390      32637.242234\n",
      "#arctober            28   88179.678571  100329.859598      26187.089886\n",
      "#arcane              96  118157.343750  188802.478099      25828.373487\n",
      "#arcanefics           2   10195.000000    5730.393355       9279.888915\n",
      "#riotgames            2   10195.000000    5730.393355       9279.888915\n"
     ]
    }
   ],
   "source": [
    "# Sort by normalized impact\n",
    "top_tags = hashtag_stats.sort_values('normalized_score', ascending=False)\n",
    "print(top_tags.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71688d8f",
   "metadata": {},
   "source": [
    "- Even after normalizaiton, the most affective hashtag at garnering views was #leagueoflegends\n",
    "- Shorts should thereby have this hashtag by default whenever possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341be25b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
